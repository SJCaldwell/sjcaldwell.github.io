<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Infosec's Data Problem | Shane Caldwell</title>
<meta name=keywords content="machine-learning,cybersecurity,datasets,malware-detection"><meta name=description content="Exploring the fundamental data sharing challenges that limit machine learning progress in information security, and why the field needs its own ImageNet moment."><meta name=author content="Shane Caldwell"><link rel=canonical href=https://hackbot.dad/writing/infosecs-data-problem/><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://hackbot.dad/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://hackbot.dad/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://hackbot.dad/favicon-32x32.png><link rel=apple-touch-icon href=https://hackbot.dad/apple-touch-icon-180x180.png><link rel=mask-icon href=https://hackbot.dad/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://hackbot.dad/writing/infosecs-data-problem/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=icon type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon-180x180.png><link rel=apple-touch-icon href=/apple-touch-icon.png><link rel="shortcut icon" href=/favicon.ico><meta name=msapplication-TileColor content="#000000"><meta name=theme-color content="#000000"><script data-goatcounter=https://sjcaldwell.goatcounter.com/count async src=//gc.zgo.at/count.js></script><style>:root{--font-mono:'SF Mono', 'Monaco', 'Inconsolata', 'Roboto Mono', 'Source Code Pro', 'Menlo', 'Consolas', monospace}body,html{font-family:var(--font-mono)!important}*:not(mjx-container):not(mjx-container *),*:not(mjx-container):not(mjx-container *)::before,*:not(mjx-container):not(mjx-container *)::after{font-family:var(--font-mono)!important}mjx-container{overflow-x:visible!important;overflow-y:visible!important;overflow:visible!important}mjx-container[display=true]{display:block!important;text-align:center!important;margin:1em auto!important;max-width:100%!important}mjx-container[display=true] mjx-math{display:inline-block!important;text-align:left!important}mjx-container mjx-mtable{display:table!important;margin:0 auto!important;width:auto!important}mjx-container mjx-mtr{display:table-row!important;height:auto!important}mjx-container mjx-mtd{display:table-cell!important;padding:.3em .8em!important;vertical-align:middle!important}mjx-container[display=true] mjx-mtable mjx-mtr{display:table-row!important;white-space:nowrap!important}mjx-container[display=true] mjx-mtable{display:table!important;border-collapse:separate!important;border-spacing:0 .3em!important}mjx-container::-webkit-scrollbar{display:none!important}mjx-container{-ms-overflow-style:none!important;scrollbar-width:none!important}.dark{--primary:#ffffff;--secondary:#e5e5e5;--tertiary:#cccccc}body:not(.dark){--primary:#000000;--secondary:#333333;--tertiary:#666666}.dark a{color:#fff!important;text-decoration:underline}.dark a:hover{color:#e5e5e5!important}code,pre{font-family:var(--font-mono)!important;font-size:.9em}h1,h2,h3,h4,h5,h6{font-weight:700!important;color:var(--primary)!important}.post-meta{color:var(--secondary)!important}button,.button{font-family:var(--font-mono)!important;font-weight:500}.paper-card,.talk-card{background:var(--theme);border:1px solid var(--border);border-radius:8px;padding:24px;margin-bottom:24px;transition:all .2s ease;box-shadow:0 2px 4px rgba(0,0,0,5%)}.paper-card:hover,.talk-card:hover{border-color:var(--secondary);box-shadow:0 4px 8px rgba(0,0,0,.1);transform:translateY(-1px)}.dark .paper-card,.dark .talk-card{background:#1a1a1a;border-color:#333;box-shadow:0 2px 4px rgba(0,0,0,.2)}.dark .paper-card:hover,.dark .talk-card:hover{border-color:#555;box-shadow:0 4px 8px rgba(0,0,0,.3)}.paper-title{margin:0 0 12px!important;font-size:1.25em;line-height:1.3}.paper-title a{color:var(--primary)!important;text-decoration:none;border-bottom:2px solid transparent;transition:border-color .2s ease}.paper-title a:hover{border-bottom-color:var(--primary)}.paper-meta{margin-bottom:16px;font-size:.9em}.paper-authors{color:var(--secondary);margin-bottom:4px;font-weight:500}.paper-date{color:var(--tertiary);font-size:.85em}.paper-abstract{color:var(--primary);line-height:1.5}.paper-abstract p{margin:0}.talk-title{margin:0 0 12px!important;font-size:1.25em;line-height:1.3}.talk-collaborators{margin-bottom:16px;font-size:.9em;color:var(--secondary)}.talk-collaborators p{margin:0}.talk-details{display:flex;flex-direction:column;gap:8px}.talk-event,.talk-recording{font-size:.9em}.talk-recording a{color:var(--primary)!important;text-decoration:underline}.talk-recording a:hover{color:var(--secondary)!important}@media(max-width:768px){.paper-card,.talk-card{padding:16px;margin-bottom:16px}}.twitter-tweet{margin:24px auto!important;max-width:550px!important}.post-content blockquote.twitter-tweet,.post-content div:has(.twitter-tweet){display:flex;justify-content:center;margin:24px 0}.post-content .twitter-tweet iframe{margin:0 auto;display:block}.post-content figure{margin:24px 0;text-align:center}.post-content figure img{margin-bottom:12px;border-radius:6px;box-shadow:0 4px 8px rgba(0,0,0,.1);max-width:100%;height:auto}.dark .post-content figure img{box-shadow:0 4px 8px rgba(0,0,0,.3)}.post-content figcaption{font-family:var(--font-mono)!important;font-size:.85em;color:var(--secondary);font-style:italic;line-height:1.4;margin-top:8px;padding:0 16px}.post-content figcaption p{margin:0;text-align:center}@media(max-width:768px){.post-content figcaption{font-size:.8em;padding:0 8px}.post-content ol{padding-left:24px!important;margin-left:4px!important}.post-content .footnote-ref{margin-left:2px!important;margin-right:3px!important}.post-content{padding-left:20px!important;padding-right:20px!important}.main{padding-left:8px!important;padding-right:8px!important}}</style><meta property="og:url" content="https://hackbot.dad/writing/infosecs-data-problem/"><meta property="og:site_name" content="Shane Caldwell"><meta property="og:title" content="Infosec's Data Problem"><meta property="og:description" content="Exploring the fundamental data sharing challenges that limit machine learning progress in information security, and why the field needs its own ImageNet moment."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="writing"><meta property="article:published_time" content="2022-06-02T00:00:00+00:00"><meta property="article:modified_time" content="2022-06-02T00:00:00+00:00"><meta property="article:tag" content="Machine-Learning"><meta property="article:tag" content="Cybersecurity"><meta property="article:tag" content="Datasets"><meta property="article:tag" content="Malware-Detection"><meta property="og:image" content="https://hackbot.dad/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://hackbot.dad/"><meta name=twitter:title content="Infosec's Data Problem"><meta name=twitter:description content="Exploring the fundamental data sharing challenges that limit machine learning progress in information security, and why the field needs its own ImageNet moment."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Writing","item":"https://hackbot.dad/writing/"},{"@type":"ListItem","position":2,"name":"Infosec's Data Problem","item":"https://hackbot.dad/writing/infosecs-data-problem/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Infosec's Data Problem","name":"Infosec\u0027s Data Problem","description":"Exploring the fundamental data sharing challenges that limit machine learning progress in information security, and why the field needs its own ImageNet moment.","keywords":["machine-learning","cybersecurity","datasets","malware-detection"],"articleBody":"Is it possible for the most paranoid industry in technology to productively share data?\nTwo years ago I wrote a post about ML in information security. In it I cover what I think might be required to move past anomaly detection/alerting and closer to agents that can act in support of or in place of human operators. Since the time of writing, I’ve spent more time working in the industry and more time thinking about the direction the field is moving in and developed the beginnings of a gym environment for red teaming.\nAt the time I wrote that post, I thought the best way to move forward was to develop more complex, closer-to-real-world environments to train my agent in. A more and more realistic simulation. More and more realistic-looking machines in more and more realistic network configurations.\nThe algorithm I chose for my initial experiments was PPO, or Proximal Policy Optimization. This type of model is “on-policy”. A side effect of that choice is that training data cannot be re-used. Only the most recent data, or the data collected by the current model parameters (the current policy) is used to train the model at any given time. Even if I kept the state and action matrices from each timestep they would not do me or anybody else any good.\nAt the time of developing it, this didn’t bother me much, as my unstated assumption was that sharing data is out of the question for our field. No red-teamer, whether working for a corporation or independently, would dare to share that data. Even if they wanted to, the security critical nature of their work would mean that it just wasn’t possible. No employer would allow it, and certainly no client would agree to it. Imagine, for example, that you exported your entire Metasploit history for a given engagement into an action and state space of the kind I describe here. If you were to scrub host names from this data (leaving only numerical indicators: host 1 on subnet 1, or host 3 on subnet 2, etc), it would mean the following information about your engagement could be derived from those matrices:\nHow many hosts there were. The structure of the network, in what machines shared subnets/were routable to-and-from each other. What ports were open on those machines, and what exploits were successfully run against those hosts/services. That some machines existed on some network that were vulnerable to some exploits wouldn’t seem to qualify as a smoking gun security risk, but it’s certainly more than I would be comfortable with as a client. If someone with access to that data could determine the identity of the sender (pentester) and determine what client that tester had been working with at the time it would give them a decent mapping of the network and its holes at that timestep. And that’s just for reinforcement learning! Since my time writing that post, I’ve wondered if Transformers could not be trained directly on multi-modal data coming from the terminal/browser with the training occurring directly on that, instead. It’s in vogue, it would probably be pretty fruitful as research, but that data’s even harder to get. The required fidelity is yet greater, and what someone might learn from it is even more likely to prevent a sound-minded person from ever sharing it. So why bother working on it?\nSimilarly, I’ve recently been working on ML-based static malware classification. I’ve found that subfield plagued by a similar data problem. End-to-end deep learning solutions, at least those being published academically, are losing to their feature-engineered peers. MLSec 2021, a for-dollar-prizes competition to see who could classify malware best was won by a Random Forest! No knock against the Secret team for their models, it’s great work, but in my experience it’s only possible for these methods to outperform deep learning when the distribution you’re modeling is simple or the datasets are small. But why should the datasets for malware classification be small? There are enormous amounts of unique malware samples, well over a billion of them! And yet there is no “benchmark malware classification” dataset.\nOne of the big boons to deep learning, the thing that pushes forward technical progress, is benchmark datasets. The ideal benchmark dataset is difficult enough that substantive progress on it requires serious breakthroughs. ImageNet, for example, was a large and broad enough dataset such that doing classification well required the creation of convolutional neural nets. When researchers refer to the ImageNet Moment they’re referring to the 2012 rendition of the ImageNet classification challenge where AlexNet won the competition with over a 10% lead to all of its competitors, and would spawn 80,000 citations and a whole slew of technical innovation in the years to follow. But ImageNet itself was created in 2009. Would computer vision have had the same boon without ImageNet creating the bar with which all algorithms were measured? We can’t know for sure, but it’s clear that Yann LeCun’s work in the late 80s on CNNs had been largely ignored until its success in AlexNet. Perhaps the benchmark dataset and its challenge were a pre-requisite.\nIf we can take that as an example of a benchmark’s importance, computer vision isn’t alone. DeepMind’s AlphaFold was a gigantic step forward for a very different problem: protein folding. This too is based on a longstanding competition, CASP (Critical Assessment of Protein Structure Prediction). If you’ll allow a looser definition of “benchmark dataset” DARPA Grand Challenge shaped the development of self-driving. The list goes on.\nThe MLSec competition on the other hand, provides about fifty samples. Any model you can deliver is perfectly acceptable, but the data you collect must be your own. That considered, my opinion is that the MLSec competition is just as much of, if not more of, a dataset collection challenge than it is a modeling challenge. There’s some evidence to back that up. Andy Applebaum has a very interesting talk about his own process of earning third place, that he gave at CactusCon this year. At around 11:08, Andy describes trying to collect more malware/goodware for this challenge. Acquiring a dataset seems to have absorbed the vast majority of his time, and there was never enough of it.\nThis problem isn’t limited to these competitions. It’s true academically as well. Both the feature engineering and deep learning methods refer to datasets created with industry partners that they can’t share access to. The EMBER paper refers explicitly to performing better than MalConvNet against their test dataset. But you can’t pull the data and test that for yourself, you just have to take their word for it. Two algorithms compared on different test sets don’t prove anything - the comparisons are barely meaningful.\nThis isn’t their fault, obviously. Hosting malware might be a bit of a faux pas, but that’s probably easier. The malware authors don’t have intellectual property lawyers! The commercial goodware on the other hand, does, and hosting the raw binaries for the sake of ‘research’ won’t fly. So papers are published and competitions are won with datasets you can’t see, comparing test results you can’t replicate. The field suffers as a result.\nFrom this it seems clear that without making large, representative, shareable datasets the field will not make progress, at least not publicly. Further technical achievements will belong to only those private organizations who can afford to buy access to data for large sums of money and guard it as the moat that their products are built on.\nI don’t think that’s healthy.\nPhreakAI will be following EleutherAI’s inspiration with the pile in gathering and hosting large datasets for infosec. These might not quite match the inference distribution, but it would be a start.\nIf you’re interested, join the PhreakAI Discord. It might be fun.\n","wordCount":"1298","inLanguage":"en","image":"https://hackbot.dad/","datePublished":"2022-06-02T00:00:00Z","dateModified":"2022-06-02T00:00:00Z","author":{"@type":"Person","name":"Shane Caldwell"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://hackbot.dad/writing/infosecs-data-problem/"},"publisher":{"@type":"Organization","name":"Shane Caldwell","logo":{"@type":"ImageObject","url":"https://hackbot.dad/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hackbot.dad/ accesskey=h title="Shane Caldwell (Alt + H)">Shane Caldwell</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hackbot.dad/ title=Main><span>Main</span></a></li><li><a href=https://hackbot.dad/papers/ title=Papers><span>Papers</span></a></li><li><a href=https://hackbot.dad/talks/ title=Talks><span>Talks</span></a></li><li><a href=https://hackbot.dad/writing/ title=Writing><span>Writing</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Infosec's Data Problem</h1><div class=post-description>Exploring the fundamental data sharing challenges that limit machine learning progress in information security, and why the field needs its own ImageNet moment.</div><div class=post-meta><span title='2022-06-02 00:00:00 +0000 UTC'>June 2, 2022</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1298 words&nbsp;·&nbsp;Shane Caldwell</div></header><div class=post-content><p>Is it possible for the most paranoid industry in technology to productively share data?</p><p>Two years ago I wrote a post about <a href=https://sjcaldwell.github.io/writing/towards-autonomous-pentesting/>ML in information security</a>. In it I cover what I think might be required to move past anomaly detection/alerting and closer to agents that can act in support of or in place of human operators. Since the time of writing, I&rsquo;ve spent more time working in the industry and more time thinking about the direction the field is moving in and developed the beginnings of <a href=https://github.com/phreakAI/MetasploitGym>a gym environment for red teaming</a>.</p><p>At the time I wrote that post, I thought the best way to move forward was to develop more complex, closer-to-real-world environments to train my agent in. A more and more <em>realistic simulation</em>. More and more <em>realistic-looking</em> machines in more and more <em>realistic</em> network configurations.</p><p>The algorithm I chose for my initial experiments was PPO, or Proximal Policy Optimization. This type of model is &ldquo;on-policy&rdquo;. A side effect of that choice is that training data cannot be re-used. Only the most recent data, or the data collected by the current model parameters (the current <em>policy</em>) is used to train the model at any given time. Even if I kept the state and action matrices from each timestep they would not do me or anybody else any good.</p><p>At the time of developing it, this didn&rsquo;t bother me much, as my unstated assumption was that sharing data is out of the question for our field. No red-teamer, whether working for a corporation or independently, would dare to share that data. Even if they wanted to, the security critical nature of their work would mean that it just wasn&rsquo;t possible. No employer would allow it, and certainly no client would agree to it. Imagine, for example, that you exported your entire Metasploit history for a given engagement into an action and state space of the kind I describe <a href="https://www.youtube.com/watch?v=EiI69BdWKPs">here</a>. If you were to scrub host names from this data (leaving only numerical indicators: host 1 on subnet 1, or host 3 on subnet 2, etc), it would mean the following information about your engagement could be derived from those matrices:</p><ol><li>How many hosts there were.</li><li>The structure of the network, in what machines shared subnets/were routable to-and-from each other.</li><li>What ports were open on those machines, and what exploits were successfully run against those hosts/services.</li></ol><p>That some machines existed on some network that were vulnerable to some exploits wouldn&rsquo;t seem to qualify as a smoking gun security risk, but it&rsquo;s certainly more than I would be comfortable with as a client. If someone with access to that data could determine the identity of the sender (pentester) and determine what client that tester had been working with at the time it would give them a decent mapping of the network and its holes at that timestep. And that&rsquo;s just for reinforcement learning! Since my time writing that post, I&rsquo;ve wondered if Transformers could not be trained directly on multi-modal data coming from the terminal/browser with the training occurring directly on that, instead. It&rsquo;s in vogue, it would probably be pretty fruitful as research, but that data&rsquo;s even harder to get. The required fidelity is yet greater, and what someone might learn from it is even more likely to prevent a sound-minded person from ever sharing it. So why bother working on it?</p><p>Similarly, I&rsquo;ve recently been working on ML-based static malware classification. I&rsquo;ve found that subfield plagued by a similar data problem. End-to-end deep learning solutions, at least those being published academically, are losing to their feature-engineered peers. <a href=https://mlsec.io/>MLSec 2021</a>, a for-dollar-prizes competition to see who could classify malware best was won by a <a href=https://secret.inf.ufpr.br/2021/09/29/adversarial-machine-learning-malware-detection-and-the-2021s-mlsec-competition/>Random Forest</a>! No knock against the Secret team for their models, it&rsquo;s great work, but in my experience it&rsquo;s only possible for these methods to outperform deep learning when the distribution you&rsquo;re modeling is simple or the datasets are small. But why should the datasets for malware classification be small? There are enormous amounts of unique malware samples, well over <a href=https://www.av-test.org/en/statistics/malware/>a billion</a> of them! And yet there is no &ldquo;benchmark malware classification&rdquo; dataset.</p><p>One of the big boons to deep learning, the thing that pushes forward technical progress, is benchmark datasets. The ideal benchmark dataset is difficult enough that substantive progress on it requires serious breakthroughs. ImageNet, for example, was a large and broad enough dataset such that doing classification well required the creation of convolutional neural nets. When researchers refer to the <a href=https://image-net.org/challenges/LSVRC/2012/>ImageNet Moment</a> they&rsquo;re referring to the 2012 rendition of the ImageNet classification challenge where <a href=https://en.wikipedia.org/wiki/AlexNet>AlexNet</a> won the competition with over a 10% lead to all of its competitors, and would spawn 80,000 citations and a whole slew of technical innovation in the years to follow. But ImageNet itself was created in 2009. Would computer vision have had the same boon without ImageNet creating the bar with which all algorithms were measured? We can&rsquo;t know for sure, but it&rsquo;s clear that Yann LeCun&rsquo;s work in the late 80s on CNNs had been largely ignored until its success in AlexNet. Perhaps the benchmark dataset and its challenge were a pre-requisite.</p><p>If we can take that as an example of a benchmark&rsquo;s importance, computer vision isn&rsquo;t alone. <a href=https://www.deepmind.com/blog/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology>DeepMind&rsquo;s AlphaFold</a> was a gigantic step forward for a very different problem: protein folding. This too is based on a longstanding competition, CASP (Critical Assessment of Protein Structure Prediction). If you&rsquo;ll allow a looser definition of &ldquo;benchmark dataset&rdquo; <a href=https://en.wikipedia.org/wiki/DARPA_Grand_Challenge>DARPA Grand Challenge</a> shaped the development of self-driving. The list goes on.</p><p>The MLSec competition on the other hand, provides about fifty samples. Any model you can deliver is perfectly acceptable, but the data you collect must be your own. That considered, my opinion is that the MLSec competition is just as much of, if not more of, a <em>dataset collection</em> challenge than it is a modeling challenge. There&rsquo;s some evidence to back that up. Andy Applebaum has a very interesting talk about his own process of earning third place, <a href="https://www.youtube.com/watch?v=kKHP76_P8Nw">that he gave at CactusCon this year</a>. At around 11:08, Andy describes trying to collect more malware/goodware for this challenge. Acquiring a dataset seems to have absorbed the vast majority of his time, and there was never enough of it.</p><p>This problem isn&rsquo;t limited to these competitions. It&rsquo;s true academically as well. Both the feature engineering and deep learning methods refer to datasets created with industry partners that they can&rsquo;t share access to. The EMBER paper refers explicitly to performing better than MalConvNet against their test dataset. But you can&rsquo;t pull the data and test that for yourself, you just have to take their word for it. Two algorithms compared on different test sets don&rsquo;t prove anything - the comparisons are barely meaningful.</p><p>This isn&rsquo;t their fault, obviously. Hosting malware might be a bit of a faux pas, but that&rsquo;s probably easier. The malware authors don&rsquo;t have intellectual property lawyers! The commercial goodware on the other hand, does, and hosting the raw binaries for the sake of &lsquo;research&rsquo; won&rsquo;t fly. So papers are published and competitions are won with datasets you can&rsquo;t see, comparing test results you can&rsquo;t replicate. The field suffers as a result.</p><p>From this it seems clear that without making large, representative, shareable datasets the field will not make progress, at least not publicly. Further technical achievements will belong to only those private organizations who can afford to buy access to data for large sums of money and guard it as the moat that their products are built on.</p><p>I don&rsquo;t think that&rsquo;s healthy.</p><p>PhreakAI will be following <a href=https://pile.eleuther.ai/>EleutherAI&rsquo;s inspiration with the pile</a> in gathering and hosting large datasets for infosec. These might not quite match the <a href=https://en.wikipedia.org/wiki/Reality>inference distribution</a>, but it would be a start.</p><p>If you&rsquo;re interested, join the PhreakAI Discord. It might be fun.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://hackbot.dad/tags/machine-learning/>Machine-Learning</a></li><li><a href=https://hackbot.dad/tags/cybersecurity/>Cybersecurity</a></li><li><a href=https://hackbot.dad/tags/datasets/>Datasets</a></li><li><a href=https://hackbot.dad/tags/malware-detection/>Malware-Detection</a></li></ul><nav class=paginav><a class=prev href=https://hackbot.dad/writing/prompt-injection/><span class=title>« Prev</span><br><span>The Input Sanitization Perspective on Prompt Injection</span>
</a><a class=next href=https://hackbot.dad/writing/towards-autonomous-pentesting/><span class=title>Next »</span><br><span>Deep Reinforcement Learning for Security: Toward an Autonomous Pentesting Agent</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://hackbot.dad/>Shane Caldwell</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><style>.copy-code{display:inline-flex;align-items:center;justify-content:center;width:32px;height:32px;background:var(--tertiary);border:1px solid var(--border);border-radius:6px;color:var(--secondary);cursor:pointer;transition:all .2s ease;position:absolute;top:8px;right:8px;z-index:10}.copy-code:hover{background:var(--secondary);color:var(--theme)}.copy-code svg{width:16px;height:16px}.copy,.highlight .copy{display:none!important}pre{position:relative}</style><script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll('.copy, [class*="copy"]').forEach(e=>{e.classList.contains("copy-code")||e.remove()});const e=document.querySelectorAll("pre");e.forEach(e=>{const t=e.cloneNode(!0);e.parentNode.replaceChild(t,e)}),document.querySelectorAll("pre code").forEach(e=>{const n=e.parentElement;if(n.querySelector(".copy-code"))return;const t=document.createElement("button");t.classList.add("copy-code"),t.setAttribute("aria-label","Copy code"),t.setAttribute("type","button");const s=`<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"/><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"/></svg>`,a=`<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20 6L9 17l-5-5"/></svg>`;t.innerHTML=s;function o(){t.innerHTML=a,t.style.color="#10b981",setTimeout(()=>{t.innerHTML=s,t.style.color=""},2e3)}t.addEventListener("click",function(t){t.preventDefault(),t.stopPropagation();const n=e.textContent||e.innerText;navigator.clipboard?navigator.clipboard.writeText(n).then(()=>{o()}).catch(()=>{i(n)}):i(n)});function i(e){const t=document.createElement("textarea");t.value=e,t.style.position="fixed",t.style.opacity="0",document.body.appendChild(t),t.select();try{document.execCommand("copy"),o()}catch(e){console.error("Copy failed:",e)}document.body.removeChild(t)}n.appendChild(t)})})</script><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},chtml:{scale:1,mtextInheritFont:!1,matchFontHeight:!1},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]},startup:{pageReady:()=>MathJax.startup.defaultPageReady().then(()=>{document.querySelectorAll("mjx-container").forEach(e=>{e.style.overflow="visible"})})}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js></script><style>.footnote-popup{position:absolute;background:var(--theme);border:1px solid var(--border);border-radius:6px;padding:12px 16px;max-width:300px;font-size:.85em;line-height:1.4;z-index:1000;box-shadow:0 4px 12px rgba(0,0,0,.15);font-family:var(--font-mono);color:var(--primary);display:none;pointer-events:auto;word-wrap:break-word}.dark .footnote-popup{background:#2d2d2d;box-shadow:0 4px 12px rgba(0,0,0,.3)}.footnote-popup::before{content:'';position:absolute;top:-6px;left:50%;transform:translateX(-50%);width:12px;height:12px;background:var(--theme);border:1px solid var(--border);border-bottom:none;border-right:none;rotate:45deg}.dark .footnote-popup::before{background:#2d2d2d}.footnote-ref{text-decoration:none!important;font-weight:700;padding:2px 6px;border-radius:4px;background:var(--primary);color:var(--theme)!important;transition:all .2s ease;position:relative;border:1px solid var(--border);font-size:.8em;line-height:1.2;display:inline-block;min-width:18px;text-align:center;margin:0 1px;vertical-align:baseline}.footnote-ref:hover{background:var(--secondary);color:var(--theme)!important;box-shadow:0 2px 4px rgba(0,0,0,.2)}.dark .footnote-ref{background:#fff;color:#000!important;border:1px solid #666}.dark .footnote-ref:hover{background:#e5e5e5;color:#000!important;box-shadow:0 2px 6px rgba(0,0,0,.4)}</style><script>document.addEventListener("DOMContentLoaded",function(){let e=null,t=null;function s(e,t){const n=document.createElement("div");return n.className="footnote-popup",n.innerHTML=t,document.body.appendChild(n),n}function o(n,s){t&&(clearTimeout(t),t=null);const i=n.getBoundingClientRect(),r=s.getBoundingClientRect();let o=i.left+i.width/2-s.offsetWidth/2,a=i.top-s.offsetHeight-10;o<10&&(o=10),o+s.offsetWidth>window.innerWidth-10&&(o=window.innerWidth-s.offsetWidth-10),a<10&&(a=i.bottom+10),s.style.left=o+window.scrollX+"px",s.style.top=a+window.scrollY+"px",s.style.display="block",e=s}function n(){t=setTimeout(()=>{e&&(e.style.display="none",e=null)},150)}document.querySelectorAll("a.footnote-ref").forEach(e=>{const i=e.getAttribute("href");if(!i)return;const r=document.querySelector(i.replace(/:/g,"\\:"));if(!r)return;const c=r.innerHTML.replace(/<a[^>]*href="#fnref[^"]*"[^>]*>.*?<\/a>/g,"").trim();if(!c)return;const a=s(i,c);e.addEventListener("mouseenter",()=>{o(e,a)}),e.addEventListener("mouseleave",n),a.addEventListener("mouseenter",()=>{t&&(clearTimeout(t),t=null)}),a.addEventListener("mouseleave",n)}),window.addEventListener("scroll",()=>{e&&(e.style.display="none",e=null)})})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>